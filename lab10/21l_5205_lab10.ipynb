{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "vKxIMhzJsDaz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a synthetic dataset with 300 samples and 2 features\n",
        "data = make_blobs(n_samples=300, centers=4, n_features=2, random_state=42)\n",
        "# Standardize the dataset\n",
        "scaler = StandardScaler()\n",
        "data_scaled = scaler.fit_transform(data[0])"
      ],
      "metadata": {
        "id": "N8OYJ8DzsLOJ"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_centroids(data, k):\n",
        "    # Randomly select k data points as initial centroids\n",
        "    # Your implementation here\n",
        "    np.random.shuffle(data)\n",
        "    centroids = data[:k]\n",
        "    return centroids\n",
        "\n",
        "def compute_distances(data, centroids):\n",
        "    # Compute distances between data points and centroids\n",
        "    # Your implementation here\n",
        "    distances = np.zeros((len(data), len(centroids)))\n",
        "    for i, point in enumerate(data):\n",
        "        for j, centroid in enumerate(centroids):\n",
        "            distances[i, j] = np.linalg.norm(point - centroid)\n",
        "    return distances\n",
        "\n",
        "\n",
        "def assign_clusters(distances):\n",
        "    # Assign each data point to the closest centroid\n",
        "    # Your implementation here\n",
        "    return np.argmin(distances, axis=1)\n",
        "\n",
        "\n",
        "def update_centroids(data, clusters, k):\n",
        "    # Update centroids by computing the mean of points in each cluster\n",
        "    # Your implementation here\n",
        "    new_centroids = np.zeros((k, data.shape[1]))\n",
        "    for i in range(k):\n",
        "        cluster_points = data[clusters == i]\n",
        "        if len(cluster_points) > 0:\n",
        "            new_centroids[i] = np.mean(cluster_points, axis=0)\n",
        "        else:\n",
        "            # If no points in the cluster, keep the old one\n",
        "            new_centroids[i] = centroids[i]\n",
        "    return new_centroids\n",
        "\n",
        "\n",
        "def k_means(data, k, max_iterations=100):\n",
        "    centroids = initialize_centroids(data, k)\n",
        "    for _ in range(max_iterations):\n",
        "        distances = compute_distances(data, centroids)\n",
        "        clusters = assign_clusters(distances)\n",
        "        new_centroids = update_centroids(data, clusters, k)\n",
        "        if np.allclose(centroids, new_centroids):\n",
        "            break\n",
        "        centroids = new_centroids\n",
        "    return centroids, clusters\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#main or random usage\n",
        "np.random.seed(42)\n",
        "data = np.random.rand(100, 2)\n",
        "k = 3\n",
        "centroids, clusters = k_means(data, k)\n",
        "print(\"Final centroids:\")\n",
        "print(centroids)\n",
        "print(\"\\nCluster assignments for each data point:\")\n",
        "print(clusters)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATL3AFpysMkI",
        "outputId": "f2572c8f-1c78-4a3b-9ec3-34bc27a16d30"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final centroids:\n",
            "[[0.8039633  0.57026999]\n",
            " [0.18520943 0.72228065]\n",
            " [0.36376248 0.20008043]]\n",
            "\n",
            "Cluster assignments for each data point:\n",
            "[0 2 2 1 2 2 2 2 1 0 0 0 2 1 2 2 2 0 0 0 2 1 1 1 1 0 1 2 1 0 2 1 1 0 2 2 2\n",
            " 2 0 0 1 1 0 1 2 0 0 0 0 2 2 1 2 2 0 0 0 0 2 0 2 1 0 0 1 0 1 1 2 1 0 0 2 1\n",
            " 2 0 2 0 0 1 1 2 0 1 0 0 1 1 1 2 0 0 2 0 2 0 0 2 2 1]\n"
          ]
        }
      ]
    }
  ]
}